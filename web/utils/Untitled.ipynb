{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "import pycuda.autoinit  # This is needed for initializing CUDA driver\n",
    "import numpy as np\n",
    "from utils.ssd_classes import get_cls_dict\n",
    "from utils.display import open_window, set_display, show_fps\n",
    "from utils.visualization import BBoxVisualization\n",
    "import ctypes\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_trt(img, shape=(300, 300)):\n",
    "    \"\"\"Preprocess an image before TRT SSD inferencing.\"\"\"\n",
    "    img = cv2.resize(img, shape)\n",
    "    img = img.transpose((2, 0, 1)).astype(np.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "def _postprocess_trt(img, output, conf_th, output_layout):\n",
    "    \"\"\"Postprocess TRT SSD output.\"\"\"\n",
    "    img_h, img_w, _ = img.shape\n",
    "    boxes, confs, clss = [], [], []\n",
    "    #print(len(output))\n",
    "    for prefix in range(0, len(output), output_layout):\n",
    "        index = int(output[prefix+0])\n",
    "        conf = float(output[prefix+2])\n",
    "        if conf < conf_th:\n",
    "            continue\n",
    "        x1 = int(output[prefix+3] * img_w)\n",
    "        y1 = int(output[prefix+4] * img_h)\n",
    "        x2 = int(output[prefix+5] * img_w)\n",
    "        y2 = int(output[prefix+6] * img_h)\n",
    "        cls = int(output[prefix+1])\n",
    "        boxes.append((x1, y1, x2, y2))\n",
    "        confs.append(conf)\n",
    "        clss.append(cls)\n",
    "    return boxes, confs, clss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrtSSD(object):\n",
    "    \"\"\"TrtSSD class encapsulates things needed to run TRT SSD.\"\"\"\n",
    "    #加载自定义组建，这里如果TensorRT版本小于7.0需要额外生成flattenconcat的自定义组件库\n",
    "    def _load_plugins(self):\n",
    "        #if trt.__version__[0] < '7':\n",
    "        #    ctypes.CDLL(\"ssd/libflattenconcat.so\")\n",
    "        trt.init_libnvinfer_plugins(self.trt_logger, '')\n",
    "    #加载通过Transfer Learning Toolkit生成的推理引擎\n",
    "    def _load_engine(self):\n",
    "        TRTbin = 'ssd/TRT_%s.bin' % self.model\n",
    "        with open(TRTbin, 'rb') as f, trt.Runtime(self.trt_logger) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "    #通过加载的引擎，生成可执行的上下文\n",
    "    def _create_context(self):\n",
    "        for binding in self.engine:\n",
    "            size = trt.volume(self.engine.get_binding_shape(binding)) * \\\n",
    "                   self.engine.max_batch_size\n",
    "            ##注意：这里的host_mem需要时用pagelocked memory，以免内存被释放\n",
    "            host_mem = cuda.pagelocked_empty(size, np.float32)\n",
    "            cuda_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            self.bindings.append(int(cuda_mem))\n",
    "            if self.engine.binding_is_input(binding):\n",
    "                self.host_inputs.append(host_mem)\n",
    "                self.cuda_inputs.append(cuda_mem)\n",
    "            else:\n",
    "                self.host_outputs.append(host_mem)\n",
    "                self.cuda_outputs.append(cuda_mem)\n",
    "        return self.engine.create_execution_context()\n",
    "    #初始化引擎\n",
    "    def __init__(self, model, input_shape, output_layout=7):\n",
    "        \"\"\"Initialize TensorRT plugins, engine and conetxt.\"\"\"\n",
    "        self.model = model\n",
    "        self.input_shape = input_shape\n",
    "        self.output_layout = output_layout\n",
    "        self.trt_logger = trt.Logger(trt.Logger.INFO)\n",
    "        self._load_plugins()\n",
    "        self.engine = self._load_engine()\n",
    "\n",
    "        self.host_inputs = []\n",
    "        self.cuda_inputs = []\n",
    "        self.host_outputs = []\n",
    "        self.cuda_outputs = []\n",
    "        self.bindings = []\n",
    "        self.stream = cuda.Stream()\n",
    "        self.context = self._create_context()\n",
    "    #释放引擎，释放GPU显存，释放CUDA流\n",
    "    def __del__(self):\n",
    "        \"\"\"Free CUDA memories.\"\"\"\n",
    "        del self.stream\n",
    "        del self.cuda_outputs\n",
    "        del self.cuda_inputs\n",
    "    #利用生成的可执行上下文执行推理\n",
    "    def detect(self, img, conf_th=0.3):\n",
    "        \"\"\"Detect objects in the input image.\"\"\"\n",
    "        img_resized = _preprocess_trt(img, self.input_shape)\n",
    "        np.copyto(self.host_inputs[0], img_resized.ravel())\n",
    "        #将处理好的图片从CPU内存中复制到GPU显存\n",
    "        cuda.memcpy_htod_async(\n",
    "            self.cuda_inputs[0], self.host_inputs[0], self.stream)\n",
    "        #开始执行推理任务\n",
    "        self.context.execute_async(\n",
    "            batch_size=1,\n",
    "            bindings=self.bindings,\n",
    "            stream_handle=self.stream.handle)\n",
    "        #将推理结果输出从GPU显存复制到CPU内存\n",
    "        cuda.memcpy_dtoh_async(\n",
    "            self.host_outputs[1], self.cuda_outputs[1], self.stream)\n",
    "        cuda.memcpy_dtoh_async(\n",
    "            self.host_outputs[0], self.cuda_outputs[0], self.stream)\n",
    "        self.stream.synchronize()\n",
    "\n",
    "\n",
    "        output = self.host_outputs[0]\n",
    "        #for x in output:\n",
    "        #    print(str(x),end=' ')\n",
    "        return _postprocess_trt(img, output, conf_th, self.output_layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(video, trt_ssd, conf_th, vis,result_file_name):\n",
    "    full_scrn = False\n",
    "    fps = 0.0\n",
    "    tic = time.time()\n",
    "    ##定义输入编码\n",
    "    fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')\n",
    "    videoWriter = cv2.VideoWriter('result.AVI', fourcc, 30, (544,960))\n",
    "    ##开始循环检测，并将结果写到result.mp4中\n",
    "    while True:\n",
    "        ret,img = video.read()\n",
    "        if img is not None:\n",
    "            boxes, confs, clss = trt_ssd.detect(img, conf_th)\n",
    "            img = vis.draw_bboxes(img, boxes, confs, clss)\n",
    "            videoWriter.write(img)\n",
    "            toc = time.time()\n",
    "            curr_fps = 1.0 / (toc - tic)\n",
    "            fps = curr_fps if fps == 0.0 else (fps*0.95 + curr_fps*0.05)\n",
    "            tic = toc\n",
    "            print(\"\\rfps: \"+str(fps),end=\"\")\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop():   \n",
    "    filename = \"face_mask_test_video.mp4\"\n",
    "    result_file_name = str(filename)\n",
    "    video = cv2.VideoCapture(filename)\n",
    "    cls_dict = get_cls_dict(\"ssd_mobilenet_v2_face\".split('_')[-1])\n",
    "    model_name =\"ssd_mobilenet_v2_face\"\n",
    "    trt_ssd = TrtSSD(model_name, (300,300))\n",
    "    vis = BBoxVisualization(cls_dict)\n",
    "    print(\"start detection!\")\n",
    "    detect_video(video, trt_ssd, conf_th=0.3, vis=vis, result_file_name=result_file_name)\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\nfinish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i result.AVI -vcodec libx264 -f mp4 result-ffmpeg.mp4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"result-ffmpeg.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
